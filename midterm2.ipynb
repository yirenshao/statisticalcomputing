{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Sta 663 - Statistical Computing and Computation - Midterm 2\n",
    "-----------\n",
    "Due Wednesday, April 28th by 5:00 pm.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load necessary packages\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Task 1 - `newton()` function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, check whether the objective or derivatives are finite at the initial theta. Within each iteration (until maxit), calculate the jacobian and hessian of objective at the current theta and check whether they are finite. Then check whether current objective value meets convergence and calculate the current step size. Change the current theta by the step size computed. If the current objective value got larger, then half the step size until the objective value got smaller or the maximum iterations for halfing a step was met. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def newton(theta, f, tol = 1e-8, fscale = 1.0,maxit = 100, max_half = 20):\n",
    "    \n",
    "    all_theta_i = [theta]\n",
    "    all_f_i = [f(theta)]\n",
    "    g_i = torch.autograd.functional.jacobian(f,theta)\n",
    "    if not (torch.isfinite(f(theta)) and torch.isfinite(g_i).all()):\n",
    "        raise ValueError(\"Objective function is not finite at the initial theta.\")\n",
    "    \n",
    "    \n",
    "    theta_i = theta\n",
    "    \n",
    "    for i in range(maxit):\n",
    "        f_i = f(theta_i)\n",
    "        flag_max_it = True\n",
    "        g_i = torch.autograd.functional.jacobian(f,theta_i)\n",
    "        h_i = torch.autograd.functional.hessian(f,theta_i)\n",
    "        if not torch.isfinite(g_i).all():\n",
    "            raise ValueError(\"Gradient is not finite at the initial theta.\")\n",
    "        if not torch.isfinite(h_i).all(): \n",
    "            raise ValueError(\"Hessian is not finite at the initial theta.\")\n",
    "        step = - np.linalg.solve(h_i, g_i)\n",
    "        \n",
    "        if max(abs(g_i)) < (abs(f_i)+fscale)*tol :\n",
    "            flag_max_it = False\n",
    "            break\n",
    "        \n",
    "        for j in range(max_half):\n",
    "            flag_max_half = True\n",
    "            new_theta_i = theta_i + step\n",
    "            new_f_i = f(new_theta_i)\n",
    "            if (new_f_i < all_f_i[-1]):\n",
    "                flag_max_half = False\n",
    "                break\n",
    "            step /= 2\n",
    "        \n",
    "        if flag_max_half:\n",
    "            raise ValueError(\"Max_half steps failed to reduce objective.\")\n",
    "        theta_i, f_i = new_theta_i, new_f_i\n",
    "        all_theta_i.append(theta_i)\n",
    "        all_f_i.append(f_i)\n",
    "        \n",
    "    \n",
    "    \n",
    "    if flag_max_it:\n",
    "        raise ValueError(\"Max_it reached without convergence.\")\n",
    "        \n",
    "    if not torch.linalg.cholesky_ex(h_i).info.eq(0):\n",
    "        raise ValueError(\"Hessian is not positive finite at convergence.\")\n",
    "        \n",
    "    result = {\n",
    "        \"f\": all_f_i[-1],\n",
    "        \"theta\": all_theta_i[-1],\n",
    "        \"iter\": i + 1,\n",
    "        \"grad\": g_i\n",
    "    }\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 - Minimization examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 1. Quadratic function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Objective function implementation\n",
    "Qf = lambda x: x[0]**2 - 2 * x[0] + 2 * x[1]**2 + x[1] + 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f': tensor(1.8750, dtype=torch.float64),\n",
       " 'theta': tensor([ 1.0000, -0.2500], dtype=torch.float64),\n",
       " 'iter': 2,\n",
       " 'grad': tensor([0., 0.], dtype=torch.float64)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## theta 1 minimization\n",
    "newton(torch.tensor([1.5,1],dtype = torch.double), Qf, tol = 1e-8, fscale = 1.0,maxit = 100, max_half = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f': tensor(1.8750, dtype=torch.float64),\n",
       " 'theta': tensor([ 1.0000, -0.2500], dtype=torch.float64),\n",
       " 'iter': 2,\n",
       " 'grad': tensor([0.0000e+00, 1.1102e-16], dtype=torch.float64)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## theta 2 minimization\n",
    "newton(torch.tensor([0.01,0.1],dtype = torch.double), Qf, tol = 1e-8, fscale = 1.0,maxit = 100, max_half = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f': tensor(1.8750, dtype=torch.float64),\n",
       " 'theta': tensor([ 1.0000, -0.2500], dtype=torch.float64),\n",
       " 'iter': 2,\n",
       " 'grad': tensor([0., 0.], dtype=torch.float64)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## theta 3 minimization\n",
    "newton(torch.tensor([10.1,10.1],dtype = torch.double), Qf, tol = 1e-8, fscale = 1.0,maxit = 100, max_half = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Sphere function in 10d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Objective function implementation\n",
    "Sf = lambda x: x[0]**2 + x[1]**2 + x[2]**2+ x[3]**2+ x[4]**2+ x[5]**2+ x[6]**2+ x[7]**2+ x[8]**2+ x[9]**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f': tensor(0., dtype=torch.float64),\n",
       " 'theta': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=torch.float64),\n",
       " 'iter': 2,\n",
       " 'grad': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=torch.float64)}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## theta 1 minimization\n",
    "newton(torch.tensor([1,1,1,1,1,1,1,1,1,1],dtype = torch.double), Sf, tol = 1e-8, fscale = 1.0,maxit = 100, max_half = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f': tensor(0., dtype=torch.float64),\n",
       " 'theta': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=torch.float64),\n",
       " 'iter': 2,\n",
       " 'grad': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=torch.float64)}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## theta 2 minimization\n",
    "newton(torch.tensor([1,100,10000,1,10,10,-1,10,1,10],dtype = torch.double), Sf, fscale = 1.0,tol = 1e-8, maxit = 100, max_half = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f': tensor(0., dtype=torch.float64),\n",
       " 'theta': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=torch.float64),\n",
       " 'iter': 2,\n",
       " 'grad': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=torch.float64)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## theta 3 minimization\n",
    "newton(torch.tensor([-1,-1,10000,1000000,1000,10000,1000,-100,1000,1000],dtype = torch.double), Sf, tol = 1e-8, fscale = 1.0,maxit = 100, max_half = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Rosenbrock's function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Objective function implementation\n",
    "Rf = lambda x: 100 * (x[1] - x[0]**2)**2 + (1-x[0])**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f': tensor(1.1093e-31, dtype=torch.float64),\n",
       " 'theta': tensor([1.0000, 1.0000], dtype=torch.float64),\n",
       " 'iter': 16,\n",
       " 'grad': tensor([-6.6613e-16,  0.0000e+00], dtype=torch.float64)}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## theta 1 minimization\n",
    "newton(torch.tensor([0.01,0.1],dtype = torch.double), Rf, tol = 1e-8, fscale = 1.0,maxit = 100, max_half = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f': tensor(1.4787e-20, dtype=torch.float64),\n",
       " 'theta': tensor([1.0000, 1.0000], dtype=torch.float64),\n",
       " 'iter': 53,\n",
       " 'grad': tensor([ 4.2357e-09, -2.1725e-09], dtype=torch.float64)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## theta 2 minimization\n",
    "newton(torch.tensor([-10,-100],dtype = torch.double), Rf, tol = 1e-8,fscale = 1.0, maxit = 100, max_half = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f': tensor(1.2331e-28, dtype=torch.float64),\n",
       " 'theta': tensor([1.0000, 1.0000], dtype=torch.float64),\n",
       " 'iter': 16,\n",
       " 'grad': tensor([ 1.1058e-13, -4.4409e-14], dtype=torch.float64)}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## theta 3 minimization\n",
    "newton(torch.tensor([2,2],dtype = torch.double), Rf, tol = 1e-8, fscale = 1.0,maxit = 100, max_half = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Rosenbrockâ€™s function in 4d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4d Rosenbrock's function might have more than one minima so that Newton fails with inappropriate starting point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Objective function implementation\n",
    "Rf_4d = lambda x: 100 * (x[1] - x[0]**2)**2 + (1-x[0])**2 + 100 * (x[2] - x[1]**2)**2 + (1-x[1])**2 + 100 * (x[3] - x[2]**2)**2 + (1-x[2])**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f': tensor(6.7748e-28, dtype=torch.float64),\n",
       " 'theta': tensor([1.0000, 1.0000, 1.0000, 1.0000], dtype=torch.float64),\n",
       " 'iter': 21,\n",
       " 'grad': tensor([ 1.8696e-13, -7.1054e-14,  6.5725e-13, -3.1086e-13],\n",
       "        dtype=torch.float64)}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## theta 1 minimization\n",
    "newton(torch.tensor([2,2,2,2],dtype = torch.double), Rf_4d, tol = 1e-8, fscale = 1.0,maxit = 100, max_half = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Step failed to reduce the objective after max_half step halvings.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m## theta 2 minimization\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mnewton\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdouble\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mRf_4d\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1e-8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mfscale\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxit\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_half\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 37\u001b[0m, in \u001b[0;36mnewton\u001b[0;34m(theta, f, tol, fscale, maxit, max_half)\u001b[0m\n\u001b[1;32m     34\u001b[0m     step \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m flag_max_half:\n\u001b[0;32m---> 37\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStep failed to reduce the objective after max_half step halvings.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     38\u001b[0m theta_i, f_i \u001b[38;5;241m=\u001b[39m new_theta_i, new_f_i\n\u001b[1;32m     39\u001b[0m all_theta_i\u001b[38;5;241m.\u001b[39mappend(theta_i)\n",
      "\u001b[0;31mValueError\u001b[0m: Step failed to reduce the objective after max_half step halvings."
     ]
    }
   ],
   "source": [
    "## theta 2 minimization\n",
    "newton(torch.tensor([-2,-2,-2,-2],dtype = torch.double), Rf_4d, tol = 1e-8,fscale = 1.0, maxit = 100, max_half = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f': tensor(5.9868e-27, dtype=torch.float64),\n",
       " 'theta': tensor([1.0000, 1.0000, 1.0000, 1.0000], dtype=torch.float64),\n",
       " 'iter': 24,\n",
       " 'grad': tensor([ 1.1324e-14,  8.9040e-14,  2.2160e-13, -2.2204e-13],\n",
       "        dtype=torch.float64)}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## theta 3 minimization\n",
    "newton(torch.tensor([-2,-2,-2,2],dtype = torch.double), Rf_4d, tol = 1e-8,fscale = 1.0, maxit = 100, max_half = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Beale function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### The Beale function is nonconvex and multimodal, with sharp peaks at the corners of the input domain. The point newton method is trying to find might be the saddle point and convergence is not assured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Objective function implementation\n",
    "Bf = lambda x : (1.5 - x[0] + x[0] * x[1])**2 + (2.25 - x[0] + x[0]*x[1]**2)**2 + (2.625 - x[0] + x[0]*x[1]**3)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Step failed to reduce the objective after max_half step halvings.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m## theta 1 minimization\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mnewton\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdouble\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1e-8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mfscale\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxit\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_half\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 37\u001b[0m, in \u001b[0;36mnewton\u001b[0;34m(theta, f, tol, fscale, maxit, max_half)\u001b[0m\n\u001b[1;32m     34\u001b[0m     step \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m flag_max_half:\n\u001b[0;32m---> 37\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStep failed to reduce the objective after max_half step halvings.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     38\u001b[0m theta_i, f_i \u001b[38;5;241m=\u001b[39m new_theta_i, new_f_i\n\u001b[1;32m     39\u001b[0m all_theta_i\u001b[38;5;241m.\u001b[39mappend(theta_i)\n",
      "\u001b[0;31mValueError\u001b[0m: Step failed to reduce the objective after max_half step halvings."
     ]
    }
   ],
   "source": [
    "## theta 1 minimization\n",
    "newton(torch.tensor([-1,-1],dtype = torch.double), Bf, tol = 1e-8,fscale = 1.0, maxit = 100, max_half = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Step failed to reduce the objective after max_half step halvings.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m## theta 2 minimization\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mnewton\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdouble\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1e-8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscale\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mmaxit\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_half\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 37\u001b[0m, in \u001b[0;36mnewton\u001b[0;34m(theta, f, tol, fscale, maxit, max_half)\u001b[0m\n\u001b[1;32m     34\u001b[0m     step \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m flag_max_half:\n\u001b[0;32m---> 37\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStep failed to reduce the objective after max_half step halvings.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     38\u001b[0m theta_i, f_i \u001b[38;5;241m=\u001b[39m new_theta_i, new_f_i\n\u001b[1;32m     39\u001b[0m all_theta_i\u001b[38;5;241m.\u001b[39mappend(theta_i)\n",
      "\u001b[0;31mValueError\u001b[0m: Step failed to reduce the objective after max_half step halvings."
     ]
    }
   ],
   "source": [
    "## theta 2 minimization\n",
    "newton(torch.tensor([2,1],dtype = torch.double), Bf, tol = 1e-8, fscale = 1.0,maxit = 100, max_half = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f': tensor(1.3960e-27, dtype=torch.float64),\n",
       " 'theta': tensor([3.0000, 0.5000], dtype=torch.float64),\n",
       " 'iter': 7,\n",
       " 'grad': tensor([-4.1467e-14,  2.5280e-13], dtype=torch.float64)}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## theta 3 minimization\n",
    "newton(torch.tensor([2,0],dtype = torch.double), Bf, tol = 1e-8,fscale = 1.0, maxit = 100, max_half = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 6. Poisson regression likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\begin{aligned} \\log \\lambda_i &= \\beta_0 + \\beta_1 x_i \\ L(\\beta_0,\\beta_1) &= \\prod_{i=1}^{10}\\frac{\\lambda_i^{y_i} e^{-\\lambda_i}}{y_i!} \\ l(\\beta_0,\\beta_1) &= \\sum_{i=1}^{10} y_i \\log \\lambda_i - \\lambda_i - \\log y_i! \\end{aligned} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [\n",
    "   0.11, -0.06, -0.96, -0.48, -0.59, -0.42, -0.15,  1.14, 0.94, \n",
    "  -0.86, -0.08,  1.00, -2.01,  2.17, -0.20,  0.82, -0.13, 0.26, \n",
    "   0.22,  1.05\n",
    "]\n",
    "\n",
    "y = [4, 2, 4, 1, 1, 3, 4, 5, 7, 3, 5, 7, 0, 4, 2, 7, 3, 3, 2, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Objective function implementation\n",
    "l = lambda beta: -(y[0] * (beta[0] + beta[1] * x[0]) - torch.exp(beta[0] + beta[1] * x[0]) - torch.log(torch.exp(torch.lgamma(torch.tensor([y[0] + 1],dtype = torch.double))))+\n",
    "     y[1] * (beta[0] + beta[1] * x[1]) - torch.exp(beta[0] + beta[1] * x[1]) - torch.log(torch.exp(torch.lgamma(torch.tensor([y[1] + 1],dtype = torch.double))))+\n",
    "     y[2] * (beta[0] + beta[1] * x[2]) - torch.exp(beta[0] + beta[1] * x[2]) - torch.log(torch.exp(torch.lgamma(torch.tensor([y[2] + 1],dtype = torch.double))))+\n",
    "     y[3] * (beta[0] + beta[1] * x[3]) - torch.exp(beta[0] + beta[1] * x[3]) - torch.log(torch.exp(torch.lgamma(torch.tensor([y[3] + 1],dtype = torch.double))))+\n",
    "     y[4] * (beta[0] + beta[1] * x[4]) - torch.exp(beta[0] + beta[1] * x[4]) - torch.log(torch.exp(torch.lgamma(torch.tensor([y[4] + 1],dtype = torch.double))))+\n",
    "     y[5] * (beta[0] + beta[1] * x[5]) - torch.exp(beta[0] + beta[1] * x[5]) - torch.log(torch.exp(torch.lgamma(torch.tensor([y[5] + 1],dtype = torch.double))))+\n",
    "     y[6] * (beta[0] + beta[1] * x[6]) - torch.exp(beta[0] + beta[1] * x[6]) - torch.log(torch.exp(torch.lgamma(torch.tensor([y[6] + 1],dtype = torch.double))))+\n",
    "     y[7] * (beta[0] + beta[1] * x[7]) - torch.exp(beta[0] + beta[1] * x[7]) - torch.log(torch.exp(torch.lgamma(torch.tensor([y[7] + 1],dtype = torch.double))))+\n",
    "     y[8] * (beta[0] + beta[1] * x[8]) - torch.exp(beta[0] + beta[1] * x[8]) - torch.log(torch.exp(torch.lgamma(torch.tensor([y[8] + 1],dtype = torch.double))))+\n",
    "     y[9] * (beta[0] + beta[1] * x[9]) - torch.exp(beta[0] + beta[1] * x[9]) - torch.log(torch.exp(torch.lgamma(torch.tensor([y[9] + 1],dtype = torch.double)))))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f': tensor(17.6547, dtype=torch.float64),\n",
       " 'theta': tensor([1.2340, 0.4660], dtype=torch.float64),\n",
       " 'iter': 5,\n",
       " 'grad': tensor([ 3.2648e-08, -1.7604e-08], dtype=torch.float64)}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## theta 1 minimization\n",
    "newton(torch.tensor([1,1],dtype = torch.double), l, tol = 1e-8, fscale = 1.0,maxit = 100, max_half = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f': tensor(17.6547, dtype=torch.float64),\n",
       " 'theta': tensor([1.2340, 0.4660], dtype=torch.float64),\n",
       " 'iter': 19,\n",
       " 'grad': tensor([6.9362e-09, 6.4082e-09], dtype=torch.float64)}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## theta 2 minimization\n",
    "newton(torch.tensor([5,10],dtype = torch.double), l, tol = 1e-8, fscale = 1.0,maxit = 100, max_half = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f': tensor(17.6547, dtype=torch.float64),\n",
       " 'theta': tensor([1.2340, 0.4660], dtype=torch.float64),\n",
       " 'iter': 7,\n",
       " 'grad': tensor([ 2.5381e-09, -1.3687e-09], dtype=torch.float64)}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## theta 3 minimization\n",
    "newton(torch.tensor([-1,-1],dtype = torch.double), l, tol = 1e-8,fscale = 1.0, maxit = 100, max_half = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
